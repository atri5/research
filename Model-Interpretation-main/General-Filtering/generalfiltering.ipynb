{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import os\n",
    "from scipy.io import savemat\n",
    "t0 = timeit.default_timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atrip\\AppData\\Local\\Temp\\ipykernel_35860\\756110595.py:4: DtypeWarning: Columns (16,17,19,20,24,25,26,27,29,31,32,33,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened file in: 36.0507465 seconds.\n",
      "Index(['SubjectID', 'IRB', 'Instrument', 'PrimaryAnatomy',\n",
      "       'Patient_LevelInclude_Exclude', 'Setup', 'Age', 'Sex', 'Ethnicity',\n",
      "       'Race',\n",
      "       ...\n",
      "       'Phasor_SH3_ch2_1', 'Phasor_GH1_ch3_1', 'Phasor_SH1_ch3_1',\n",
      "       'Phasor_GH2_ch3_1', 'Phasor_SH2_ch3_1', 'Phasor_GH3_ch3_1',\n",
      "       'Phasor_SH3_ch3_1', 'Tob_label', 'Alc_label', 'ML_label'],\n",
      "      dtype='object', length=125)\n",
      "[ 0 20 31 25  2 42 19 11 17 38 24 28 37 35  9 34  8 10 15 12 22 27 36 29\n",
      " 30  5 40 46 41]\n"
     ]
    }
   ],
   "source": [
    "#Specify file name\n",
    "file = r'C:\\Users\\atrip\\Research\\Model-Interpretation-main\\Data\\HN_P2C_20241212.csv'\n",
    "checkpoints = 1\n",
    "df = pd.read_csv(file)\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Opened file in: \"+ str(t1 - t0) + \" seconds.\")\n",
    "print(df.columns)\n",
    "print(df['WLI_4'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Using a .mat file\n",
    "\n",
    "# import h5py\n",
    "\n",
    "# with h5py.File('e:\\AYUSH\\Large File Downloads\\HN_P2C_20240522_no_iRFcap_no_CFDBug.mat', 'r') as file:\n",
    "#     group_key = list(file.keys())[2]\n",
    "#     data = list(file[group_key])\n",
    "\n",
    "#     # Convert to DataFrame\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "# print(\"hi\")\n",
    "# print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shows first few dataplots in df\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint #1 at: 92.80776239999999 seconds.\n"
     ]
    }
   ],
   "source": [
    "#removes In Vivo filtering\n",
    "\n",
    "filtered_data = df[df['ScanContext'] == 'In Vivo']\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Checkpoint #\" + str(checkpoints) +  \" at: \"+str(t1-t0)+ \" seconds.\")\n",
    "checkpoints += 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SubjectID', 'IRB', 'Instrument', 'PrimaryAnatomy',\n",
      "       'Patient_LevelInclude_Exclude', 'Setup', 'Age', 'Sex', 'Ethnicity',\n",
      "       'Race',\n",
      "       ...\n",
      "       'Phasor_SH3_ch2_1', 'Phasor_GH1_ch3_1', 'Phasor_SH1_ch3_1',\n",
      "       'Phasor_GH2_ch3_1', 'Phasor_SH2_ch3_1', 'Phasor_GH3_ch3_1',\n",
      "       'Phasor_SH3_ch3_1', 'Tob_label', 'Alc_label', 'ML_label'],\n",
      "      dtype='object', length=125)\n"
     ]
    }
   ],
   "source": [
    "#Relabelling for sanity:\n",
    "\n",
    "df.rename(columns={'TobbacoStatus': 'TobaccoStatus'}, inplace=True)\n",
    "\n",
    "if('snr_ch1_1' in df.columns):\n",
    "    df.rename(columns={'WLI_4':'Label','snr_ch1_1':'snr_ch1', 'snr_ch2_1':'snr_ch2', 'snr_ch3_1':'snr_ch3', 'gain_ch1_1':'gain_ch1',  'gain_ch2_1':'gain_ch2',  'gain_ch3_1':'gain_ch3' , 'spec_int_ch1_1':'spec_int_ch1', 'spec_int_ch2_1':'spec_int_ch2', 'spec_int_ch3_1':'spec_int_ch3'},inplace = True)\n",
    "    df.rename(columns={'lifet_avg_ch1_1':'lifet_avg_ch1','lifet_avg_ch2_1':'lifet_avg_ch2', 'lifet_avg_ch3_1':'lifet_avg_ch3', 'int_ratio_ch1_1':'int_ratio_ch1', 'int_ratio_ch2_1':'int_ratio_ch2', 'int_ratio_ch3_1':'int_ratio_ch3'},inplace=True)\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint #2 at: 99.92249869999999 seconds.\n"
     ]
    }
   ],
   "source": [
    "#drops columns 13-28\n",
    "df.drop(df.columns[12:28], axis=1)\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Checkpoint #\" + str(checkpoints) + \" at: \"+str(t1-t0)+ \" seconds.\")\n",
    "checkpoints += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove certain patients\n",
    "# df = df[df['Case'] != 124]\n",
    "# df = df[df['Case'] < 160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removes CH4 data\n",
    "df = df[df['DataChannelsUsed'] != 'CH4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#SNR Thresholding (previous was  > 30/50 respectively, now do > 40/40)\n",
    "SNR_Thr_V4 = 40\n",
    "SNR_Thr_FB = 40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint #3 at: 129.8944514 seconds.\n"
     ]
    }
   ],
   "source": [
    "#removes V4/FLImBrush data\n",
    "\n",
    "mask = (\n",
    "    ((df['snr_ch1'] < SNR_Thr_V4) & (df['Instrument'] == 'V4')) |\n",
    "    ((df['snr_ch2'] < SNR_Thr_V4) & (df['Instrument'] == 'V4')) |\n",
    "    ((df['snr_ch3'] < SNR_Thr_V4) & (df['Instrument'] == 'V4'))\n",
    ")\n",
    "\n",
    "df = df[~mask]\n",
    "\n",
    "mask2 = (\n",
    "    ((df['snr_ch1'] < SNR_Thr_FB) & (df['Instrument'] == 'FLImBrush')) |\n",
    "    ((df['snr_ch2'] < SNR_Thr_FB) & (df['Instrument'] == 'FLImBrush')) |\n",
    "    ((df['snr_ch3'] < SNR_Thr_FB) & (df['Instrument'] == 'FLImBrush'))\n",
    ")\n",
    "\n",
    "df = df[~mask2]\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Checkpoint #\" + str(checkpoints) + \" at: \"+str(t1-t0)+ \" seconds.\")\n",
    "checkpoints += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint #4 at: 134.9205241 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing entries in specific columns (NaN values)\n",
    "df = df.dropna(subset=['lifet_avg_ch1', 'lifet_avg_ch2', 'lifet_avg_ch3'])\n",
    "df = df.dropna(subset=['int_ratio_ch1', 'int_ratio_ch2', 'int_ratio_ch3'])\n",
    "\n",
    "#remove data with the 0 label\n",
    "df = df[df['Label'] != 0]\n",
    "\n",
    "#Remove data with negative int values\n",
    "df = df[~((df['lifet_avg_ch1'] < 0) | (df['lifet_avg_ch2'] < 0) | (df['lifet_avg_ch3'] < 0))]\n",
    "df = df[~((df['spec_int_ch1'] < 0) | (df['spec_int_ch2'] < 0) | (df['spec_int_ch3'] < 0))]\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Checkpoint #\" + str(checkpoints) + \" at: \"+str(t1-t0)+ \" seconds.\")\n",
    "checkpoints += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint #5at: 143.99553070000002 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Normalizing intensity ratios for V4 to be comparable to FLImBrush\n",
    "\n",
    "total_spec_int = df['spec_int_ch1'] + df['spec_int_ch2'] + df['spec_int_ch3']\n",
    "IR_ch1 = 0.1877 * (df['spec_int_ch1'] / total_spec_int)\n",
    "IR_ch2 = 0.8108 * (df['spec_int_ch2'] / total_spec_int)\n",
    "IR_ch3 = 1.4116 * (df['spec_int_ch3'] / total_spec_int)\n",
    "\n",
    "## Calculate Int_ratio_ch1, Int_ratio_ch2, and Int_ratio_ch3\n",
    "total_IR = IR_ch1 + IR_ch2 + IR_ch3\n",
    "Int_ratio_ch1 = IR_ch1 / total_IR\n",
    "Int_ratio_ch2 = IR_ch2 / total_IR\n",
    "Int_ratio_ch3 = IR_ch3 / total_IR\n",
    "\n",
    "condition = df['Instrument'] == 'V4'\n",
    "df.loc[condition, 'int_ratio_ch1'] = Int_ratio_ch1[condition]\n",
    "df.loc[condition, 'int_ratio_ch2'] = Int_ratio_ch2[condition]\n",
    "df.loc[condition, 'int_ratio_ch3'] = Int_ratio_ch3[condition]\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Checkpoint #\" + str(checkpoints) + \"at: \"+str(t1-t0)+ \" seconds.\")\n",
    "checkpoints += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Additional Filtering for gain\n",
    "\n",
    "df = df[df['gain_ch1'] < 300]\n",
    "df = df[df['gain_ch2'] < 500]\n",
    "df = df[df['gain_ch3'] < 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to file...\n",
      "Directory './HN_P2C_files/' was created.\n",
      "Saved to ./HN_P2C_files/modified_ml_labelled_HN_P2C_20241212.csv. Finished in 245.0700636 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving to file...\")\n",
    "# Gets dir and saves to local folder \n",
    "script_dir = './HN_P2C_files/'\n",
    "file_base = 'modified_' + os.path.basename(file)\n",
    "\n",
    "if not os.path.exists(script_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(script_dir)\n",
    "    print(f\"Directory '{script_dir}' was created.\")\n",
    "\n",
    "output_file_path = os.path.join(script_dir + file_base)\n",
    "# df.to_csv(output_file_path, index=False)\n",
    "# #deletes old csv(comment out if not needed)\n",
    "# file_to_delete = os.path.join(script_dir, file)\n",
    "# if os.path.exists(file_to_delete):\n",
    "\n",
    "#for saving as csv \n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "#for saving as mat(takes longer but smaller file size)\n",
    "#file_base = 'modified_' + os.path.basename(file)[:-4] + '.mat'\n",
    "# data_to_save = {col: df[col].values for col in df.columns}\n",
    "# savemat(output_file_path, data_to_save)\n",
    "\n",
    "t1 = timeit.default_timer()\n",
    "print(\"Saved to \" + output_file_path + \". Finished in \" + str(t1-t0) + \" seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
